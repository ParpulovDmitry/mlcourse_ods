{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению\n",
    "</center>\n",
    "<center>Автор материала: программист-исследователь Mail.ru Group, старший преподаватель <br>Факультета Компьютерных Наук ВШЭ Юрий Кашницкий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашнее задание № 8. Часть 2\n",
    "## <center> Vowpal Wabbit в задаче классификации тегов вопросов на Stackoverflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План 2 части домашнего задания\n",
    "    2.1. Введение\n",
    "    2.2. Описание данных\n",
    "    2.3. Предобработка данных\n",
    "    2.4. Обучение и проверка моделей\n",
    "    2.5. Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Введение\n",
    "\n",
    "В этом задании вы будете делать примерно то же, что я каждую неделю –  в Mail.ru Group: обучать модели на выборке в несколько гигабайт. Задание можно выполнить и на Windows с Python, но я рекомендую поработать под \\*NIX-системой (например, через Docker) и активно использовать язык bash.\n",
    "Немного снобизма (простите, но правда): если вы захотите работать в лучших компаниях мира в области ML, вам все равно понадобится опыт работы с bash под UNIX.\n",
    "\n",
    "[Веб-форма](https://goo.gl/forms/z8zENbMiaEAeB7nG3) для ответов.\n",
    "\n",
    "Для выполнения задания понадобится установленный Vowpal Wabbit (уже есть в докер-контейнере курса, см. инструкцию в README [репозитория](https://github.com/Yorko/mlcourse_open) нашего курса) и примерно 70 Гб дискового пространства. Я тестировал решение не на каком-то суперкомпе, а на Macbook Pro 2015 (8 ядер, 16 Гб памяти), и самая тяжеловесная модель обучалась около 12 минут, так что задание реально выполнить и с простым железом. Но если вы планируете когда-либо арендовать сервера Amazon, можно попробовать это сделать уже сейчас.\n",
    "\n",
    "Материалы в помощь:\n",
    " - интерактивный [тьюториал](https://www.codecademy.com/en/courses/learn-the-command-line/lessons/environment/exercises/bash-profile) CodeAcademy по утилитам командной строки UNIX (примерно на час-полтора)\n",
    " - [статья](https://habrahabr.ru/post/280562/) про то, как арендовать на Amazon машину (еще раз: это не обязательно для выполнения задания, но будет хорошим опытом, если вы это делаете впервые)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеются 10 Гб вопросов со StackOverflow – [скачайте](https://yadi.sk/d/krikdUic3Ggjyf) эту выборку. \n",
    "\n",
    "Формат данных простой:<br>\n",
    "<center>*текст вопроса* (слова через пробел) TAB *теги вопроса* (через пробел)\n",
    "\n",
    "Здесь TAB – это символ табуляции.\n",
    "Пример первой записи в выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is there a way to apply a background color through css at the tr level i can apply it at the td level like this my td background color e8e8e8 background e8e8e8 however the background color doesn t seem to get applied when i attempt to apply the background color at the tr level like this my tr background color e8e8e8 background e8e8e8 is there a css trick to making this work or does css not natively support this for some reason \tcss css3 css-selectors\r\n"
     ]
    }
   ],
   "source": [
    "!head -1 stackoverflow.10kk.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь у нас текст вопроса, затем табуляция и теги вопроса: *css, css3* и *css-selectors*. Всего в выборке таких вопросов 10 миллионов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000 stackoverflow.10kk.tsv\n",
      "CPU times: user 67 ms, sys: 10 ms, total: 77 ms\n",
      "Wall time: 3.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!wc -l stackoverflow.10kk.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на то, что такие данные я уже не хочу загружать в оперативную память и, пока можно, буду пользоваться эффективными утилитами UNIX –  head, tail, wc, cat, cut и прочими."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте выберем в наших данных все вопросы с тегами *javascript, java, python, ruby, php, c++, c#, go, scala* и  *swift* и подготовим обучающую выборку в формате Vowpal Wabbit. Будем решать задачу 10-классовой классификации вопросов по перечисленным тегам.\n",
    "\n",
    "Вообще, как мы видим, у каждого вопроса может быть несколько тегов, но мы упростим себе задачу и будем у каждого вопроса выбирать один из перечисленных тегов либо игнорировать вопрос, если таковых тегов нет. \n",
    "Но вообще VW поддерживает multilabel classification (аргумент  --multilabel_oaa).\n",
    "<br>\n",
    "<br>\n",
    "Реализуйте в виде отдельного файла `preprocess.py` код для подготовки данных. Он должен отобрать строки, в которых есть перечисленные теги, и переписать их в отдельный файл в формат Vowpal Wabbit. Детали:\n",
    " - скрипт должен работать с аргументами командной строки: с путями к файлам на входе и на выходе\n",
    " - строки обрабатываются по одной (можно использовать tqdm для подсчета числа итераций)\n",
    " - если табуляций в строке нет или их больше одной, считаем строку поврежденной и пропускаем\n",
    " - в противном случае смотрим, сколько в строке тегов из списка *javascript, java, python, ruby, php, c++, c#, go, scala* и  *swift*. Если ровно один, то записываем строку в выходной файл в формате VW: `label | text`, где `label` – число от 1 до 10 (1 - *javascript*, ... 10 – *swift*). Пропускаем те строки, где интересующих тегов больше или меньше одного \n",
    " - из текста вопроса надо выкинуть двоеточия и вертикальные палки, если они есть – в VW это спецсимволы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Должно получиться вот такое число строк – 4389054. Как видите, 10 Гб у меня обработались примерно за полторы минуты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "CPU times: user 11.3 s, sys: 1.63 s, total: 12.9 s\n",
      "Wall time: 10min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python preprocess.py -i stackoverflow.10kk.tsv -o stackoverflow.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4522552 stackoverflow.vw\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l stackoverflow.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поделите выборку на обучающую, проверочную и тестовую части в равной пропорции - по  1463018 в каждый файл. Перемешивать не надо, первые 1463018 строк должны пойти в обучающую часть `stackoverflow_train.vw`, последние 1463018 – в тестовую `stackoverflow_test.vw`, оставшиеся – в проверочную `stackoverflow_valid.vw`. \n",
    "\n",
    "Также сохраните векторы ответов для проверочной и тестовой выборки в отдельные файлы `stackoverflow_valid_labels.txt` и `stackoverflow_test_labels.txt`.\n",
    "\n",
    "Тут вам помогут утилиты `head`, `tail`, `split`, `cat` и `cut`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1507517"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4522552 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -1507517 stackoverflow.vw > stackoverflow_train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tail -1507517 stackoverflow.vw > stackoverflow_test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!head -3015035 stackoverflow.vw | tail -1507518 > stackoverflow_valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1507517 stackoverflow_train.vw\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l stackoverflow_train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1507517 stackoverflow_test.vw\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l stackoverflow_test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1507518 stackoverflow_valid.vw\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l stackoverflow_valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cut --d '|' -f1 stackoverflow_valid.vw > stackoverflow_valid_labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cut --d '|' -f1 stackoverflow_test.vw > stackoverflow_test_labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Обучение и проверка моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите Vowpal Wabbit на выборке `stackoverflow_train.vw` 9 раз, перебирая параметры passes (1,3,5), ngram (1,2,3).\n",
    "Остальные параметры укажите следующие: bit_precision=28 и seed=17. Также скажите VW, что это 10-классовая задача.\n",
    "\n",
    "Проверяйте долю правильных ответов на выборке `stackoverflow_valid.vw`. Выберите лучшую модель и проверьте качество на выборке `stackoverflow_test.vw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "with open('stackoverflow_valid_labels.txt') as true_file:\n",
    "    true_labels = [int(label) for label in true_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with 1 passes and 1 ngrams\n",
      "Running with 1 passes and 2 ngrams\n",
      "Running with 1 passes and 3 ngrams\n",
      "Running with 3 passes and 1 ngrams\n",
      "Running with 3 passes and 2 ngrams\n",
      "Running with 3 passes and 3 ngrams\n",
      "Running with 5 passes and 1 ngrams\n",
      "Running with 5 passes and 2 ngrams\n",
      "Running with 5 passes and 3 ngrams\n",
      "CPU times: user 14.3 s, sys: 134 ms, total: 14.4 s\n",
      "Wall time: 46min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "for pas in [1,3,5]:\n",
    "    for ngram in [1,2,3]:\n",
    "        print \"Running with %s passes and %s ngrams\" % (pas, ngram)\n",
    "        vw_params_train = \"--oaa 10 -d stackoverflow_train.vw -f models/model_%spass_%sngram --loss_function=hinge --passes %s -c --ngram %s -b 28 --random_seed 17\" % (pas, ngram, pas, ngram)\n",
    "        vw_params_test = \"-i models/model_%spass_%sngram -t -d stackoverflow_valid.vw -p preds/pred_%spass_%sngram.txt\" % (pas, ngram, pas, ngram)\n",
    "        \n",
    "        vw_train = os.system(\"vw \" + vw_params_train)\n",
    "        vw_test = os.system(\"vw \" + vw_params_test)\n",
    "        \n",
    "        with open('preds/pred_%spass_%sngram.txt' % (pas, ngram)) as pred_file:\n",
    "            valid_prediction = [int(label) for label in pred_file.readlines()]\n",
    "            \n",
    "        key = \"%spass_%sngram\" % (pas, ngram)\n",
    "        results[key] = accuracy_score(valid_prediction, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1pass_1ngram': 0.9006320322543413,\n",
       " '1pass_2ngram': 0.91761226068279123,\n",
       " '1pass_3ngram': 0.91482556095515943,\n",
       " '3pass_1ngram': 0.90172256649671845,\n",
       " '3pass_2ngram': 0.9146318650921581,\n",
       " '3pass_3ngram': 0.91191348959017404,\n",
       " '5pass_1ngram': 0.90102406737431995,\n",
       " '5pass_2ngram': 0.91573765620045666,\n",
       " '5pass_3ngram': 0.91259407847866492}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91761226068279123"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(results.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 pass 1 ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = models/model_3pass_1ngram\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = stackoverflow_train.vw.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      161\n",
      "0.500000 1.000000            2            2.0        4        1       68\n",
      "0.750000 1.000000            4            4.0        7        1       88\n",
      "0.750000 0.750000            8            8.0        7        1       95\n",
      "0.750000 0.750000           16           16.0        2        7      159\n",
      "0.750000 0.750000           32           32.0        1        7      404\n",
      "0.734375 0.718750           64           64.0        5        1       54\n",
      "0.664062 0.593750          128          128.0        6        6      319\n",
      "0.593750 0.523438          256          256.0        7        7      166\n",
      "0.523438 0.453125          512          512.0        2        2      186\n",
      "0.450195 0.376953         1024         1024.0        3        3      114\n",
      "0.385254 0.320312         2048         2048.0        6        6       29\n",
      "0.327393 0.269531         4096         4096.0        1        1      272\n",
      "0.272339 0.217285         8192         8192.0        3        3       48\n",
      "0.233582 0.194824        16384        16384.0        1        1      195\n",
      "0.201385 0.169189        32768        32768.0        6        6       34\n",
      "0.173904 0.146423        65536        65536.0        3        3      158\n",
      "0.154121 0.134338       131072       131072.0        3        5      126\n",
      "0.137638 0.121155       262144       262144.0        2        2      107\n",
      "0.125153 0.112667       524288       524288.0        7        7      117\n",
      "0.115777 0.106401      1048576      1048576.0        2        5      197\n",
      "0.107624 0.107624      2097152      2097152.0        1        1      102 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1356766\n",
      "passes used = 3\n",
      "weighted example sum = 4070298.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.099369 h\n",
      "total feature number = 815763021\n",
      "CPU times: user 1.32 s, sys: 163 ms, total: 1.49 s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 1 pass 1 ngram\n",
    "!vw --oaa 10 -d stackoverflow_train.vw -f models/model_3pass_1ngram \\\n",
    "--loss_function=hinge --passes 3 -c --ngram 1 -b 28 --random_seed 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1-grams for all namespaces.\n",
      "only testing\n",
      "predictions = preds/pred_3pass_1ngram.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        2        2       72\n",
      "0.000000 0.000000            2            2.0        1        1      143\n",
      "0.000000 0.000000            4            4.0        7        7      180\n",
      "0.000000 0.000000            8            8.0        5        5      116\n",
      "0.062500 0.125000           16           16.0        7        7      246\n",
      "0.093750 0.125000           32           32.0        2        2      201\n",
      "0.187500 0.281250           64           64.0        1        1       65\n",
      "0.164062 0.140625          128          128.0        7        1       22\n",
      "0.128906 0.093750          256          256.0        2        2      637\n",
      "0.126953 0.125000          512          512.0        6        6      441\n",
      "0.101562 0.076172         1024         1024.0        2        2       95\n",
      "0.098145 0.094727         2048         2048.0        6        6      174\n",
      "0.099365 0.100586         4096         4096.0        5        5      140\n",
      "0.096802 0.094238         8192         8192.0        3        3      206\n",
      "0.097168 0.097534        16384        16384.0        2        1      352\n",
      "0.099091 0.101013        32768        32768.0        1        1      208\n",
      "0.098297 0.097504        65536        65536.0        3        3       69\n",
      "0.098183 0.098068       131072       131072.0        2        2       47\n",
      "0.097782 0.097382       262144       262144.0        5        5       41\n",
      "0.097603 0.097424       524288       524288.0        2        2     1208\n",
      "0.098375 0.099148      1048576      1048576.0        1        1       58\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1507518\n",
      "passes used = 1\n",
      "weighted example sum = 1507518.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.098277\n",
      "total feature number = 302239430\n"
     ]
    }
   ],
   "source": [
    "!vw -i models/model_3pass_1ngram -t -d stackoverflow_valid.vw \\\n",
    "-p preds/pred_3pass_1ngram.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('preds/pred_3pass_1ngram.txt') as pred_file:\n",
    "    valid_prediction = [int(label) for label in pred_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.901722566497\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}\".format(accuracy_score(valid_prediction, true_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Вопрос 1.</font> Какое сочетание параметров дает наибольшую долю правильных ответов на проверочной выборке `stackoverflow_valid.vw`?\n",
    "- Биграммы и 3 прохода по выборке\n",
    "- Триграммы и 5 проходов по выборке\n",
    "- Биграммы и 1 проход по выборке\n",
    "- Униграммы и 1 проход по выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте лучшую (по доле правильных ответов на валидации) модель на тестовой выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = preds/pred_best_model_test.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        5        5      466\n",
      "0.000000 0.000000            2            2.0        1        1      264\n",
      "0.000000 0.000000            4            4.0        3        3      504\n",
      "0.000000 0.000000            8            8.0        6        6      346\n",
      "0.000000 0.000000           16           16.0        5        5      350\n",
      "0.000000 0.000000           32           32.0        1        1      320\n",
      "0.062500 0.125000           64           64.0        7        7      520\n",
      "0.093750 0.125000          128          128.0        4        4      148\n",
      "0.082031 0.070312          256          256.0        7        7      404\n",
      "0.074219 0.066406          512          512.0        1        5       76\n",
      "0.075195 0.076172         1024         1024.0        7        7     1024\n",
      "0.077637 0.080078         2048         2048.0        7        7      494\n",
      "0.080811 0.083984         4096         4096.0        2        7      188\n",
      "0.080811 0.080811         8192         8192.0        2        2      286\n",
      "0.080444 0.080078        16384        16384.0       10       10      212\n",
      "0.082367 0.084290        32768        32768.0        1        2      326\n",
      "0.083145 0.083923        65536        65536.0        1        7      376\n",
      "0.082390 0.081635       131072       131072.0        2        2      204\n",
      "0.082516 0.082642       262144       262144.0        3        3      136\n",
      "0.082752 0.082989       524288       524288.0        7        7       76\n",
      "0.082474 0.082195      1048576      1048576.0        1        1      168\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1507517\n",
      "passes used = 1\n",
      "weighted example sum = 1507517.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.082475\n",
      "total feature number = 602839386\n"
     ]
    }
   ],
   "source": [
    "!vw -i models/model_1pass_2ngram -t -d stackoverflow_test.vw -p preds/pred_best_model_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('preds/pred_best_model_test.txt') as pred_file:\n",
    "    valid_prediction = [int(label) for label in pred_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stackoverflow_test_labels.txt') as true_file:\n",
    "    true_labels_test = [int(label) for label in true_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.917525308172\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}\".format(accuracy_score(valid_prediction, true_labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## validation Accuracy: 91.761226068279123\n",
    "## test Accuracy: 91.7525308172"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Вопрос 2.</font> Как соотносятся доли правильных ответов лучшей (по доле правильных ответов на валидации) модели на проверочной и на тестовой выборках? (здесь % – это процентный пункт, т.е., скажем, снижение с 50% до 40% – это на 10%, а не 20%).\n",
    "- На тестовой ниже примерно на 2%\n",
    "- На тестовой ниже примерно на 3%\n",
    "- Результаты почти одинаковы – отличаются меньше чем на 0.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите VW с параметрами, подобранными на проверочной выборке, теперь на объединении обучающей и проверочной выборок. Посчитайте долю правильных ответов на тестовой выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat stackoverflow_train.vw stackoverflow_valid.vw > stackoverflow_big_train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = models/final_model_1pass_2ngram\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "creating cache_file = stackoverflow_big_train.vw.cache\n",
      "Reading datafile = stackoverflow_big_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      320\n",
      "0.500000 1.000000            2            2.0        4        1      134\n",
      "0.750000 1.000000            4            4.0        7        1      174\n",
      "0.750000 0.750000            8            8.0        7        1      188\n",
      "0.750000 0.750000           16           16.0        7        7      416\n",
      "0.781250 0.812500           32           32.0        7        2      346\n",
      "0.734375 0.687500           64           64.0        7        2      248\n",
      "0.640625 0.546875          128          128.0        2        2      124\n",
      "0.609375 0.578125          256          256.0        5        1      164\n",
      "0.556641 0.503906          512          512.0        1        1      148\n",
      "0.461914 0.367188         1024         1024.0        6        6      468\n",
      "0.381836 0.301758         2048         2048.0        7        7      474\n",
      "0.319336 0.256836         4096         4096.0        7        7      164\n",
      "0.268677 0.218018         8192         8192.0        2        2      192\n",
      "0.225708 0.182739        16384        16384.0        2        2      856\n",
      "0.189789 0.153870        32768        32768.0        1        1      108\n",
      "0.162689 0.135590        65536        65536.0        7        7      454\n",
      "0.140907 0.119125       131072       131072.0        2        2      136\n",
      "0.122810 0.104713       262144       262144.0        7        7      214\n",
      "0.111811 0.100811       524288       524288.0       10       10      410\n",
      "0.101307 0.090803      1048576      1048576.0        5        5      526\n",
      "0.092272 0.083238      2097152      2097152.0        1        1      396\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 3015035\n",
      "passes used = 1\n",
      "weighted example sum = 3015035.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.088651\n",
      "total feature number = 1203089848\n",
      "CPU times: user 3.45 s, sys: 454 ms, total: 3.9 s\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 1 pass 2 ngram\n",
    "!vw --oaa 10 -d stackoverflow_big_train.vw -f models/final_model_1pass_2ngram \\\n",
    "--loss_function=hinge --passes 1 -c --ngram 2 -b 28 --random_seed 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = preds/pred_final_model_test.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        5        5      466\n",
      "0.000000 0.000000            2            2.0        1        1      264\n",
      "0.000000 0.000000            4            4.0        3        3      504\n",
      "0.000000 0.000000            8            8.0        6        6      346\n",
      "0.000000 0.000000           16           16.0        5        5      350\n",
      "0.000000 0.000000           32           32.0        1        1      320\n",
      "0.062500 0.125000           64           64.0        7        7      520\n",
      "0.062500 0.062500          128          128.0        4        4      148\n",
      "0.046875 0.031250          256          256.0        7        7      404\n",
      "0.060547 0.074219          512          512.0        1        5       76\n",
      "0.079102 0.097656         1024         1024.0        7        7     1024\n",
      "0.075684 0.072266         2048         2048.0        7        7      494\n",
      "0.077393 0.079102         4096         4096.0        2        7      188\n",
      "0.076294 0.075195         8192         8192.0        2        2      286\n",
      "0.076294 0.076294        16384        16384.0       10       10      212\n",
      "0.077881 0.079468        32768        32768.0        1        2      326\n",
      "0.078522 0.079163        65536        65536.0        1        1      376\n",
      "0.078018 0.077515       131072       131072.0        2        2      204\n",
      "0.078548 0.079079       262144       262144.0        3        3      136\n",
      "0.078581 0.078613       524288       524288.0        7        2       76\n",
      "0.078328 0.078075      1048576      1048576.0        1        1      168\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1507517\n",
      "passes used = 1\n",
      "weighted example sum = 1507517.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.078160\n",
      "total feature number = 602839386\n"
     ]
    }
   ],
   "source": [
    "!vw -i models/final_model_1pass_2ngram -t -d stackoverflow_test.vw -p preds/pred_final_model_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('preds/pred_final_model_test.txt') as pred_file:\n",
    "    valid_prediction = [int(label) for label in pred_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.921840350722\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}\".format(accuracy_score(valid_prediction, true_labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Было Accuracy: 0.917525308172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4315042550000072"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "92.1840350722 - 91.7525308172"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Вопрос 3.</font> На сколько процентных пунктов повысилась доля правильных ответов модели после обучения на вдвое большей выборке (обучающая `stackoverflow_train.vw` + проверочная `stackoverflow_valid.vw`) по сравнению с моделью, обученной только на `stackoverflow_train.vw`?\n",
    " - 0.1%\n",
    " - 0.4%\n",
    " - 0.8%\n",
    " - 1.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы только познакомились с Vowpal Wabbit. Что еще можно попробовать:\n",
    " - Классификация с несколькими ответами (multilabel classification, аргумент  `multilabel_oaa`) – формат данных тут как раз под такую задачу\n",
    " - Настройка параметров VW с hyperopt, авторы библиотеки утверждают, что качество должно сильно зависеть от параметров изменения шага градиентного спуска (`initial_t` и `power_t`). Также можно потестировать разные функции потерь – обучать логистическую регресиию или линейный SVM\n",
    " - Познакомиться с факторизационными машинами и их реализацией в VW (аргумент `lrq`)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
